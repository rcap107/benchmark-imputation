{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook is used to clean up and prepare the datasets used in\n",
    "[ATTENTION-BASED LEARNING FOR MISSING DATA IMPUTATION IN HOLOCLEAN](https://proceedings.mlsys.org/paper/2020/file/202cb962ac59075b964b07152d234b70-Paper.pdf)\n",
    "to use them for our imputation experiments.\n",
    "\n",
    "The datasets have a number of of different formats and each of them will require different cleanup procedures.\n",
    "\n",
    "I'll gather all datasets here for clarity."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Some paths\n",
    "data_dir = 'data/new_datasets'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_df(dataset_name, data_dir, null_value=None):\n",
    "    this_dir = osp.join(data_dir, dataset_name)\n",
    "    df = pd.read_csv(osp.join(this_dir, f'{dataset_name}.csv'), sep=' ')\n",
    "    if null_value is not None:\n",
    "        df = df.replace(null_value, np.nan)\n",
    "    df.describe(include='all')\n",
    "    return df\n",
    "\n",
    "def get_clean_df(df):\n",
    "    print('Location of nulls')\n",
    "    print(df.isna().sum())\n",
    "    df_nonulls = df.dropna()\n",
    "    print(f'Shape of full dataset: {df.shape}')\n",
    "    print(f'Shape of cleaned dataset: {df_nonulls.shape}')\n",
    "    return df_nonulls\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Australian\n",
    "https://archive.ics.uci.edu/ml/datasets/statlog+(australian+credit+approval)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "               A1          A2          A3          A4          A5          A6  \\\ncount  690.000000  690.000000  690.000000  690.000000  690.000000  690.000000   \nmean     0.678261   31.568203    4.758725    1.766667    7.372464    4.692754   \nstd      0.467482   11.853273    4.978163    0.430063    3.683265    1.992316   \nmin      0.000000   13.750000    0.000000    1.000000    1.000000    1.000000   \n25%      0.000000   22.670000    1.000000    2.000000    4.000000    4.000000   \n50%      1.000000   28.625000    2.750000    2.000000    8.000000    4.000000   \n75%      1.000000   37.707500    7.207500    2.000000   10.000000    5.000000   \nmax      1.000000   80.250000   28.000000    3.000000   14.000000    9.000000   \n\n               A7          A8          A9        A10         A11         A12  \\\ncount  690.000000  690.000000  690.000000  690.00000  690.000000  690.000000   \nmean     2.223406    0.523188    0.427536    2.40000    0.457971    1.928986   \nstd      3.346513    0.499824    0.495080    4.86294    0.498592    0.298813   \nmin      0.000000    0.000000    0.000000    0.00000    0.000000    1.000000   \n25%      0.165000    0.000000    0.000000    0.00000    0.000000    2.000000   \n50%      1.000000    1.000000    0.000000    0.00000    0.000000    2.000000   \n75%      2.625000    1.000000    1.000000    3.00000    1.000000    2.000000   \nmax     28.500000    1.000000    1.000000   67.00000    1.000000    3.000000   \n\n               A13            A14         A15  \ncount   690.000000     690.000000  690.000000  \nmean    184.014493    1018.385507    0.444928  \nstd     172.159274    5210.102598    0.497318  \nmin       0.000000       1.000000    0.000000  \n25%      80.000000       1.000000    0.000000  \n50%     160.000000       6.000000    0.000000  \n75%     272.000000     396.500000    1.000000  \nmax    2000.000000  100001.000000    1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A1</th>\n      <th>A2</th>\n      <th>A3</th>\n      <th>A4</th>\n      <th>A5</th>\n      <th>A6</th>\n      <th>A7</th>\n      <th>A8</th>\n      <th>A9</th>\n      <th>A10</th>\n      <th>A11</th>\n      <th>A12</th>\n      <th>A13</th>\n      <th>A14</th>\n      <th>A15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>690.000000</td>\n      <td>690.000000</td>\n      <td>690.000000</td>\n      <td>690.000000</td>\n      <td>690.000000</td>\n      <td>690.000000</td>\n      <td>690.000000</td>\n      <td>690.000000</td>\n      <td>690.000000</td>\n      <td>690.00000</td>\n      <td>690.000000</td>\n      <td>690.000000</td>\n      <td>690.000000</td>\n      <td>690.000000</td>\n      <td>690.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.678261</td>\n      <td>31.568203</td>\n      <td>4.758725</td>\n      <td>1.766667</td>\n      <td>7.372464</td>\n      <td>4.692754</td>\n      <td>2.223406</td>\n      <td>0.523188</td>\n      <td>0.427536</td>\n      <td>2.40000</td>\n      <td>0.457971</td>\n      <td>1.928986</td>\n      <td>184.014493</td>\n      <td>1018.385507</td>\n      <td>0.444928</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.467482</td>\n      <td>11.853273</td>\n      <td>4.978163</td>\n      <td>0.430063</td>\n      <td>3.683265</td>\n      <td>1.992316</td>\n      <td>3.346513</td>\n      <td>0.499824</td>\n      <td>0.495080</td>\n      <td>4.86294</td>\n      <td>0.498592</td>\n      <td>0.298813</td>\n      <td>172.159274</td>\n      <td>5210.102598</td>\n      <td>0.497318</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>13.750000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>22.670000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>0.165000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>80.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>28.625000</td>\n      <td>2.750000</td>\n      <td>2.000000</td>\n      <td>8.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>160.000000</td>\n      <td>6.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>37.707500</td>\n      <td>7.207500</td>\n      <td>2.000000</td>\n      <td>10.000000</td>\n      <td>5.000000</td>\n      <td>2.625000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>3.00000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>272.000000</td>\n      <td>396.500000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>80.250000</td>\n      <td>28.000000</td>\n      <td>3.000000</td>\n      <td>14.000000</td>\n      <td>9.000000</td>\n      <td>28.500000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>67.00000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>2000.000000</td>\n      <td>100001.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'australian'\n",
    "this_dir = osp.join(data_dir, dataset_name)\n",
    "columns = [f'A{_}' for _ in range(1,16)]\n",
    "df = pd.read_csv(osp.join(this_dir, f'{dataset_name}.dat'), names=columns, sep=' ')\n",
    "\n",
    "df.describe(include='all')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "mappings = {\n",
    "    'A1': {0: 'a', 1: 'b'},\n",
    "    'A4': {1: 'p', 2: 'g', 3: 'gg'},\n",
    "    'A5': {i+1 : k for i, k in enumerate('ff,d,i,k,j,aa,m,c,w,e,q,r,cc,x'.split(','))},\n",
    "    'A6': {i+1 : k for i, k in enumerate('ff,dd,j,bb,v,n,o,h,z'.split(','))},\n",
    "    'A8': {0: 'f', 1: 't'},\n",
    "    'A9': {0: 'f', 1: 't'},\n",
    "    'A11': {0: 'f', 1: 't'},\n",
    "    'A12': {1: 's', 2: 'g', 3: 'p'},\n",
    "    'A15': {1: '+', 0: '-'}\n",
    "}\n",
    "\n",
    "for col in df.columns:\n",
    "    if col in mappings:\n",
    "        df[col] = df[col].replace(mappings[col])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "df.to_csv(osp.join(this_dir, f'{dataset_name}_clean.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Contraceptive\n",
    "https://archive.ics.uci.edu/ml/datasets/Contraceptive+Method+Choice"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "                A1           A2           A3           A4           A5  \\\ncount  1473.000000  1473.000000  1473.000000  1473.000000  1473.000000   \nmean     32.538357     2.958588     3.429735     3.261371     0.850645   \nstd       8.227245     1.014994     0.816349     2.358549     0.356559   \nmin      16.000000     1.000000     1.000000     0.000000     0.000000   \n25%      26.000000     2.000000     3.000000     1.000000     1.000000   \n50%      32.000000     3.000000     4.000000     3.000000     1.000000   \n75%      39.000000     4.000000     4.000000     4.000000     1.000000   \nmax      49.000000     4.000000     4.000000    16.000000     1.000000   \n\n                A6           A7           A8           A9          A10  \ncount  1473.000000  1473.000000  1473.000000  1473.000000  1473.000000  \nmean      0.749491     2.137814     3.133741     0.073999     1.919891  \nstd       0.433453     0.864857     0.976161     0.261858     0.876376  \nmin       0.000000     1.000000     1.000000     0.000000     1.000000  \n25%       0.000000     1.000000     3.000000     0.000000     1.000000  \n50%       1.000000     2.000000     3.000000     0.000000     2.000000  \n75%       1.000000     3.000000     4.000000     0.000000     3.000000  \nmax       1.000000     4.000000     4.000000     1.000000     3.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A1</th>\n      <th>A2</th>\n      <th>A3</th>\n      <th>A4</th>\n      <th>A5</th>\n      <th>A6</th>\n      <th>A7</th>\n      <th>A8</th>\n      <th>A9</th>\n      <th>A10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1473.000000</td>\n      <td>1473.000000</td>\n      <td>1473.000000</td>\n      <td>1473.000000</td>\n      <td>1473.000000</td>\n      <td>1473.000000</td>\n      <td>1473.000000</td>\n      <td>1473.000000</td>\n      <td>1473.000000</td>\n      <td>1473.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>32.538357</td>\n      <td>2.958588</td>\n      <td>3.429735</td>\n      <td>3.261371</td>\n      <td>0.850645</td>\n      <td>0.749491</td>\n      <td>2.137814</td>\n      <td>3.133741</td>\n      <td>0.073999</td>\n      <td>1.919891</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.227245</td>\n      <td>1.014994</td>\n      <td>0.816349</td>\n      <td>2.358549</td>\n      <td>0.356559</td>\n      <td>0.433453</td>\n      <td>0.864857</td>\n      <td>0.976161</td>\n      <td>0.261858</td>\n      <td>0.876376</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>16.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>26.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>32.000000</td>\n      <td>3.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>39.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>49.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>16.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'contraceptive'\n",
    "this_dir = osp.join(data_dir, dataset_name)\n",
    "columns = [f'A{_}' for _ in range(1,11)]\n",
    "df = pd.read_csv(osp.join(this_dir, f'cmc.data'), names=columns, sep=',')\n",
    "df.describe(include='all')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "mappings = {\n",
    "    'A2': {enum+1:v for enum, v in enumerate(['low', 'lm', 'hm', 'high'])},\n",
    "    'A3': {enum+1:v for enum, v in enumerate(['low', 'lm', 'hm', 'high'])},\n",
    "    'A5': {enum:v for enum, v in enumerate(['non-islam', 'islam'])},\n",
    "    'A6': {enum:v for enum, v in enumerate(['yes', 'no'])},\n",
    "    'A7': {enum+1:v for enum, v in enumerate(['o1', 'o2' ,'o3', 'o4'])},\n",
    "    'A8': {enum+1:v for enum, v in enumerate(['low', 'lm', 'hm', 'high'])},\n",
    "    'A9': {enum:v for enum, v in enumerate(['good', 'not-good'])},\n",
    "    'A10': {enum+1:v for enum, v in enumerate(['no-use', 'long-term', 'short-term'])},\n",
    "}\n",
    "for col in df.columns:\n",
    "    if col in mappings:\n",
    "        df[col] = df[col].replace(mappings[col])\n",
    "\n",
    "df.to_csv(osp.join(this_dir, f'{dataset_name}_clean.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Credit\n",
    "https://archive.ics.uci.edu/ml/datasets/credit+approval"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "         A1     A2          A3   A4   A5   A6   A7          A8   A9  A10  \\\ncount   678    678  690.000000  684  684  681  681  690.000000  690  690   \nunique    2    349         NaN    3    3   14    9         NaN    2    2   \ntop       b  22.67         NaN    u    g    c    v         NaN    t    f   \nfreq    468      9         NaN  519  519  137  399         NaN  361  395   \nmean    NaN    NaN    4.758725  NaN  NaN  NaN  NaN    2.223406  NaN  NaN   \nstd     NaN    NaN    4.978163  NaN  NaN  NaN  NaN    3.346513  NaN  NaN   \nmin     NaN    NaN    0.000000  NaN  NaN  NaN  NaN    0.000000  NaN  NaN   \n25%     NaN    NaN    1.000000  NaN  NaN  NaN  NaN    0.165000  NaN  NaN   \n50%     NaN    NaN    2.750000  NaN  NaN  NaN  NaN    1.000000  NaN  NaN   \n75%     NaN    NaN    7.207500  NaN  NaN  NaN  NaN    2.625000  NaN  NaN   \nmax     NaN    NaN   28.000000  NaN  NaN  NaN  NaN   28.500000  NaN  NaN   \n\n              A11  A12  A13    A14            A15  A16  \ncount   690.00000  690  690    677     690.000000  690  \nunique        NaN    2    3    170            NaN    2  \ntop           NaN    f    g  00000            NaN    -  \nfreq          NaN  374  625    132            NaN  383  \nmean      2.40000  NaN  NaN    NaN    1017.385507  NaN  \nstd       4.86294  NaN  NaN    NaN    5210.102598  NaN  \nmin       0.00000  NaN  NaN    NaN       0.000000  NaN  \n25%       0.00000  NaN  NaN    NaN       0.000000  NaN  \n50%       0.00000  NaN  NaN    NaN       5.000000  NaN  \n75%       3.00000  NaN  NaN    NaN     395.500000  NaN  \nmax      67.00000  NaN  NaN    NaN  100000.000000  NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A1</th>\n      <th>A2</th>\n      <th>A3</th>\n      <th>A4</th>\n      <th>A5</th>\n      <th>A6</th>\n      <th>A7</th>\n      <th>A8</th>\n      <th>A9</th>\n      <th>A10</th>\n      <th>A11</th>\n      <th>A12</th>\n      <th>A13</th>\n      <th>A14</th>\n      <th>A15</th>\n      <th>A16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>678</td>\n      <td>678</td>\n      <td>690.000000</td>\n      <td>684</td>\n      <td>684</td>\n      <td>681</td>\n      <td>681</td>\n      <td>690.000000</td>\n      <td>690</td>\n      <td>690</td>\n      <td>690.00000</td>\n      <td>690</td>\n      <td>690</td>\n      <td>677</td>\n      <td>690.000000</td>\n      <td>690</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2</td>\n      <td>349</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>3</td>\n      <td>14</td>\n      <td>9</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>3</td>\n      <td>170</td>\n      <td>NaN</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>b</td>\n      <td>22.67</td>\n      <td>NaN</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>NaN</td>\n      <td>t</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>g</td>\n      <td>00000</td>\n      <td>NaN</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>468</td>\n      <td>9</td>\n      <td>NaN</td>\n      <td>519</td>\n      <td>519</td>\n      <td>137</td>\n      <td>399</td>\n      <td>NaN</td>\n      <td>361</td>\n      <td>395</td>\n      <td>NaN</td>\n      <td>374</td>\n      <td>625</td>\n      <td>132</td>\n      <td>NaN</td>\n      <td>383</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.758725</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.223406</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.40000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1017.385507</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.978163</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.346513</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.86294</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5210.102598</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.00000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.165000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.00000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.750000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.00000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.207500</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.625000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.00000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>395.500000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>28.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>28.500000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>67.00000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>100000.000000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'credit'\n",
    "this_dir = osp.join(data_dir, dataset_name)\n",
    "columns = [f'A{_}' for _ in range(1,17)]\n",
    "df = pd.read_csv(osp.join(this_dir, f'crx.data'), names=columns, sep=',')\n",
    "df = df.replace('?', np.nan)\n",
    "df.describe(include='all')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of nulls\n",
      "A1     12\n",
      "A2     12\n",
      "A3      0\n",
      "A4      6\n",
      "A5      6\n",
      "A6      9\n",
      "A7      9\n",
      "A8      0\n",
      "A9      0\n",
      "A10     0\n",
      "A11     0\n",
      "A12     0\n",
      "A13     0\n",
      "A14    13\n",
      "A15     0\n",
      "A16     0\n",
      "dtype: int64\n",
      "Shape of full dataset: (690, 16)\n",
      "Shape of cleaned dataset: (653, 16)\n"
     ]
    }
   ],
   "source": [
    "print('Location of nulls')\n",
    "print(df.isna().sum())\n",
    "df_nonulls = df.dropna()\n",
    "print(f'Shape of full dataset: {df.shape}')\n",
    "print(f'Shape of cleaned dataset: {df_nonulls.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "df.to_csv(osp.join(this_dir, f'{dataset_name}_clean.csv'), index=False)\n",
    "df_nonulls.to_csv(osp.join(this_dir, f'{dataset_name}_nonulls.csv'), index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Flare\n",
    "http://archive.ics.uci.edu/ml/datasets/solar+flare\n",
    "\n",
    "There are two different .data files, I will be working on `flare.data2`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "          A1    A2    A3           A4           A5           A6           A7  \\\ncount   1066  1066  1066  1066.000000  1066.000000  1066.000000  1066.000000   \nunique     6     6     4          NaN          NaN          NaN          NaN   \ntop        H     S     O          NaN          NaN          NaN          NaN   \nfreq     331   414   477          NaN          NaN          NaN          NaN   \nmean     NaN   NaN   NaN     1.153846     2.401501     1.059099     1.404315   \nstd      NaN   NaN   NaN     0.360971     0.620584     0.320324     0.490989   \nmin      NaN   NaN   NaN     1.000000     1.000000     1.000000     1.000000   \n25%      NaN   NaN   NaN     1.000000     2.000000     1.000000     1.000000   \n50%      NaN   NaN   NaN     1.000000     2.000000     1.000000     1.000000   \n75%      NaN   NaN   NaN     1.000000     3.000000     1.000000     2.000000   \nmax      NaN   NaN   NaN     2.000000     3.000000     3.000000     2.000000   \n\n                 A8           A9     A10          A11          A12  \\\ncount   1066.000000  1066.000000  1066.0  1066.000000  1066.000000   \nunique          NaN          NaN     NaN          NaN          NaN   \ntop             NaN          NaN     NaN          NaN          NaN   \nfreq            NaN          NaN     NaN          NaN          NaN   \nmean       1.875235     1.025328     1.0     0.300188     0.046904   \nstd        0.330608     0.157194     0.0     0.835784     0.302811   \nmin        1.000000     1.000000     1.0     0.000000     0.000000   \n25%        2.000000     1.000000     1.0     0.000000     0.000000   \n50%        2.000000     1.000000     1.0     0.000000     0.000000   \n75%        2.000000     1.000000     1.0     0.000000     0.000000   \nmax        2.000000     2.000000     1.0     8.000000     5.000000   \n\n                A13  \ncount   1066.000000  \nunique          NaN  \ntop             NaN  \nfreq            NaN  \nmean       0.005629  \nstd        0.086487  \nmin        0.000000  \n25%        0.000000  \n50%        0.000000  \n75%        0.000000  \nmax        2.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A1</th>\n      <th>A2</th>\n      <th>A3</th>\n      <th>A4</th>\n      <th>A5</th>\n      <th>A6</th>\n      <th>A7</th>\n      <th>A8</th>\n      <th>A9</th>\n      <th>A10</th>\n      <th>A11</th>\n      <th>A12</th>\n      <th>A13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1066</td>\n      <td>1066</td>\n      <td>1066</td>\n      <td>1066.000000</td>\n      <td>1066.000000</td>\n      <td>1066.000000</td>\n      <td>1066.000000</td>\n      <td>1066.000000</td>\n      <td>1066.000000</td>\n      <td>1066.0</td>\n      <td>1066.000000</td>\n      <td>1066.000000</td>\n      <td>1066.000000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>6</td>\n      <td>6</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>H</td>\n      <td>S</td>\n      <td>O</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>331</td>\n      <td>414</td>\n      <td>477</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.153846</td>\n      <td>2.401501</td>\n      <td>1.059099</td>\n      <td>1.404315</td>\n      <td>1.875235</td>\n      <td>1.025328</td>\n      <td>1.0</td>\n      <td>0.300188</td>\n      <td>0.046904</td>\n      <td>0.005629</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.360971</td>\n      <td>0.620584</td>\n      <td>0.320324</td>\n      <td>0.490989</td>\n      <td>0.330608</td>\n      <td>0.157194</td>\n      <td>0.0</td>\n      <td>0.835784</td>\n      <td>0.302811</td>\n      <td>0.086487</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>1.0</td>\n      <td>8.000000</td>\n      <td>5.000000</td>\n      <td>2.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'flare'\n",
    "this_dir = osp.join(data_dir, dataset_name)\n",
    "columns = [f'A{_}' for _ in range(1,14)]\n",
    "df = pd.read_csv(osp.join(this_dir, f'flare.data2'), names=columns, sep=' ')\n",
    "df = df.replace('?', np.nan)\n",
    "df.describe(include='all')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "mappings = {\n",
    "    'A4': {1: 'reduced', 2: 'unchanged'},\n",
    "    'A5': {enum+1:v for enum, v in enumerate(['decay', 'no-growth', 'growth'])},\n",
    "    'A6': {enum+1:v for enum, v in enumerate(['nothing-as-big', 'one', 'more-activity'])},\n",
    "    'A7': {1: 'yes', 2: 'no'},\n",
    "    'A8': {1: 'yes', 2: 'no'},\n",
    "    'A9': {1: 'small', 2: 'large'},\n",
    "    'A10': {1: '<=5', 2: '>5'},\n",
    "}\n",
    "for col in df.columns:\n",
    "    if col in mappings:\n",
    "        df[col] = df[col].replace(mappings[col])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "df.to_csv(osp.join(this_dir, f'{dataset_name}_clean.csv'), index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mammogram\n",
    "http://archive.ics.uci.edu/ml/datasets/mammographic+mass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "               A1          A2          A3          A4          A5          A6\ncount  959.000000  956.000000  930.000000  913.000000  885.000000  961.000000\nmean     4.348279   55.487448    2.721505    2.796276    2.910734    0.463059\nstd      1.783031   14.480131    1.242792    1.566546    0.380444    0.498893\nmin      0.000000   18.000000    1.000000    1.000000    1.000000    0.000000\n25%      4.000000   45.000000    2.000000    1.000000    3.000000    0.000000\n50%      4.000000   57.000000    3.000000    3.000000    3.000000    0.000000\n75%      5.000000   66.000000    4.000000    4.000000    3.000000    1.000000\nmax     55.000000   96.000000    4.000000    5.000000    4.000000    1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A1</th>\n      <th>A2</th>\n      <th>A3</th>\n      <th>A4</th>\n      <th>A5</th>\n      <th>A6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>959.000000</td>\n      <td>956.000000</td>\n      <td>930.000000</td>\n      <td>913.000000</td>\n      <td>885.000000</td>\n      <td>961.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.348279</td>\n      <td>55.487448</td>\n      <td>2.721505</td>\n      <td>2.796276</td>\n      <td>2.910734</td>\n      <td>0.463059</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.783031</td>\n      <td>14.480131</td>\n      <td>1.242792</td>\n      <td>1.566546</td>\n      <td>0.380444</td>\n      <td>0.498893</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>18.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>4.000000</td>\n      <td>45.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.000000</td>\n      <td>57.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>5.000000</td>\n      <td>66.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>55.000000</td>\n      <td>96.000000</td>\n      <td>4.000000</td>\n      <td>5.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'mammogram'\n",
    "this_dir = osp.join(data_dir, dataset_name)\n",
    "columns = [f'A{_}' for _ in range(1,7)]\n",
    "df = pd.read_csv(osp.join(this_dir, f'mammographic_masses.data'), names=columns, sep=',', na_values='?')\n",
    "# df = df.replace('?', np.nan)\n",
    "df.describe(include='all')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1\n",
      "A3\n",
      "A4\n",
      "A5\n",
      "A6\n"
     ]
    }
   ],
   "source": [
    "mappings = {\n",
    "    'A1': dict(zip(range(1,6), [f'o{_}'for _ in range(1,6)])),\n",
    "    'A3': {enum+1:v for enum, v in enumerate(['round', 'oval', 'lobular', 'irregular'])},\n",
    "    'A4': {enum+1:v for enum, v in enumerate(['circumscribed', 'microlobulated', 'obscured', 'ill-defined', 'spiculated'])},\n",
    "    'A5': {enum+1:v for enum, v in enumerate(['high', 'iso', 'low', 'fat-containing', 'spiculated'])},\n",
    "    'A6': {0: 'benign', 1: 'malign'}\n",
    "}\n",
    "for col in df.columns:\n",
    "    if col in mappings:\n",
    "        print(col)\n",
    "        df[col] = df[col].replace(mappings[col])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of nulls\n",
      "A1     2\n",
      "A2     5\n",
      "A3    31\n",
      "A4    48\n",
      "A5    76\n",
      "A6     0\n",
      "dtype: int64\n",
      "Shape of full dataset: (961, 6)\n",
      "Shape of cleaned dataset: (830, 6)\n"
     ]
    }
   ],
   "source": [
    "print('Location of nulls')\n",
    "print(df.isna().sum())\n",
    "df_nonulls = df.dropna()\n",
    "print(f'Shape of full dataset: {df.shape}')\n",
    "print(f'Shape of cleaned dataset: {df_nonulls.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "df.to_csv(osp.join(this_dir, f'{dataset_name}_clean.csv'), index=False)\n",
    "df_nonulls.convert_dtypes().to_csv(osp.join(this_dir, f'{dataset_name}_nonulls.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Thoracic\n",
    "https://archive.ics.uci.edu/ml/datasets/Thoracic+Surgery+Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "         DGN        PRE4        PRE5  PRE6 PRE7 PRE8 PRE9 PRE10 PRE11 PRE14  \\\ncount    470  470.000000  470.000000   470  470  470  470   470   470   470   \nunique     7         NaN         NaN     3    2    2    2     2     2     4   \ntop     DGN3         NaN         NaN  PRZ1    F    F    F     T     F  OC12   \nfreq     349         NaN         NaN   313  439  402  439   323   392   257   \nmean     NaN    3.281638    4.568702   NaN  NaN  NaN  NaN   NaN   NaN   NaN   \nstd      NaN    0.871395   11.767857   NaN  NaN  NaN  NaN   NaN   NaN   NaN   \nmin      NaN    1.440000    0.960000   NaN  NaN  NaN  NaN   NaN   NaN   NaN   \n25%      NaN    2.600000    1.960000   NaN  NaN  NaN  NaN   NaN   NaN   NaN   \n50%      NaN    3.160000    2.400000   NaN  NaN  NaN  NaN   NaN   NaN   NaN   \n75%      NaN    3.807500    3.080000   NaN  NaN  NaN  NaN   NaN   NaN   NaN   \nmax      NaN    6.300000   86.300000   NaN  NaN  NaN  NaN   NaN   NaN   NaN   \n\n       PRE17 PRE19 PRE25 PRE30 PRE32         AGE Risk1Yr  \ncount    470   470   470   470   470  470.000000     470  \nunique     2     2     2     2     2         NaN       2  \ntop        F     F     F     T     F         NaN       F  \nfreq     435   468   462   386   468         NaN     400  \nmean     NaN   NaN   NaN   NaN   NaN   62.534043     NaN  \nstd      NaN   NaN   NaN   NaN   NaN    8.706902     NaN  \nmin      NaN   NaN   NaN   NaN   NaN   21.000000     NaN  \n25%      NaN   NaN   NaN   NaN   NaN   57.000000     NaN  \n50%      NaN   NaN   NaN   NaN   NaN   62.000000     NaN  \n75%      NaN   NaN   NaN   NaN   NaN   69.000000     NaN  \nmax      NaN   NaN   NaN   NaN   NaN   87.000000     NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DGN</th>\n      <th>PRE4</th>\n      <th>PRE5</th>\n      <th>PRE6</th>\n      <th>PRE7</th>\n      <th>PRE8</th>\n      <th>PRE9</th>\n      <th>PRE10</th>\n      <th>PRE11</th>\n      <th>PRE14</th>\n      <th>PRE17</th>\n      <th>PRE19</th>\n      <th>PRE25</th>\n      <th>PRE30</th>\n      <th>PRE32</th>\n      <th>AGE</th>\n      <th>Risk1Yr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>470</td>\n      <td>470.000000</td>\n      <td>470.000000</td>\n      <td>470</td>\n      <td>470</td>\n      <td>470</td>\n      <td>470</td>\n      <td>470</td>\n      <td>470</td>\n      <td>470</td>\n      <td>470</td>\n      <td>470</td>\n      <td>470</td>\n      <td>470</td>\n      <td>470</td>\n      <td>470.000000</td>\n      <td>470</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>DGN3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>PRZ1</td>\n      <td>F</td>\n      <td>F</td>\n      <td>F</td>\n      <td>T</td>\n      <td>F</td>\n      <td>OC12</td>\n      <td>F</td>\n      <td>F</td>\n      <td>F</td>\n      <td>T</td>\n      <td>F</td>\n      <td>NaN</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>349</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>313</td>\n      <td>439</td>\n      <td>402</td>\n      <td>439</td>\n      <td>323</td>\n      <td>392</td>\n      <td>257</td>\n      <td>435</td>\n      <td>468</td>\n      <td>462</td>\n      <td>386</td>\n      <td>468</td>\n      <td>NaN</td>\n      <td>400</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>3.281638</td>\n      <td>4.568702</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>62.534043</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>0.871395</td>\n      <td>11.767857</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.706902</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>1.440000</td>\n      <td>0.960000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>NaN</td>\n      <td>2.600000</td>\n      <td>1.960000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>57.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>NaN</td>\n      <td>3.160000</td>\n      <td>2.400000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>62.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>NaN</td>\n      <td>3.807500</td>\n      <td>3.080000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>69.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>6.300000</td>\n      <td>86.300000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>87.000000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = '''@attribute DGN {DGN3,DGN2,DGN4,DGN6,DGN5,DGN8,DGN1}\n",
    "          @attribute PRE4 numeric\n",
    "          @attribute PRE5 numeric\n",
    "          @attribute PRE6 {PRZ2,PRZ1,PRZ0}\n",
    "          @attribute PRE7 {T,F}\n",
    "          @attribute PRE8 {T,F}\n",
    "          @attribute PRE9 {T,F}\n",
    "          @attribute PRE10 {T,F}\n",
    "          @attribute PRE11 {T,F}\n",
    "          @attribute PRE14 {OC11,OC14,OC12,OC13}\n",
    "          @attribute PRE17 {T,F}\n",
    "          @attribute PRE19 {T,F}\n",
    "          @attribute PRE25 {T,F}\n",
    "          @attribute PRE30 {T,F}\n",
    "          @attribute PRE32 {T,F}\n",
    "          @attribute AGE numeric\n",
    "          @attribute Risk1Yr {T,F}'''.replace('@attribute','').split('\\n')\n",
    "columns = [_.strip().split(' ')[0] for _ in cols]\n",
    "\n",
    "dataset_name = 'thoracic'\n",
    "this_dir = osp.join(data_dir, dataset_name)\n",
    "df = pd.read_csv(osp.join(this_dir, f'ThoraricSurgery.data'), names=columns, sep=',', na_values='?')\n",
    "# df = df.replace('?', np.nan)\n",
    "df.describe(include='all')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "df.to_csv(osp.join(this_dir, f'{dataset_name}_clean.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tic tac toe\n",
    "https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "         A1   A2   A3   A4   A5   A6   A7   A8        A9\ncount   958  958  958  958  958  958  958  958       958\nunique    3    3    3    3    3    3    3    3         2\ntop       x    x    x    x    x    x    x    x  positive\nfreq    378  418  378  458  378  418  378  418       626",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A1</th>\n      <th>A2</th>\n      <th>A3</th>\n      <th>A4</th>\n      <th>A5</th>\n      <th>A6</th>\n      <th>A7</th>\n      <th>A8</th>\n      <th>A9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>958</td>\n      <td>958</td>\n      <td>958</td>\n      <td>958</td>\n      <td>958</td>\n      <td>958</td>\n      <td>958</td>\n      <td>958</td>\n      <td>958</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>378</td>\n      <td>418</td>\n      <td>378</td>\n      <td>458</td>\n      <td>378</td>\n      <td>418</td>\n      <td>378</td>\n      <td>418</td>\n      <td>626</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'tic-tac-toe'\n",
    "this_dir = osp.join(data_dir, dataset_name)\n",
    "columns = [f'A{_}' for _ in range(1,10)]\n",
    "df = pd.read_csv(osp.join(this_dir, f'tic-tac-toe.data'), names=columns, sep=',', na_values='?')\n",
    "# df = df.replace('?', np.nan)\n",
    "df.describe(include='all')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "df.to_csv(osp.join(this_dir, f'{dataset_name}_clean.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Magellan Datasets\n",
    "These datasets are taken from [The Magellan Data Repository](https://sites.google.com/site/anhaidgroup/useful-stuff/the-magellan-data-repository?authuser=0). \"True\" null values are dropped from the datasets. Apart from that, no major modifications are done."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "data_dir = 'data/new-hard'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of nulls\n",
      "id             0\n",
      "bike_name      0\n",
      "city_posted    0\n",
      "km_driven      0\n",
      "color          2\n",
      "fuel_type      0\n",
      "price          0\n",
      "model_year     0\n",
      "owner_type     0\n",
      "dtype: int64\n",
      "Shape of full dataset: (13789, 9)\n",
      "Shape of cleaned dataset: (13787, 9)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'bikes'\n",
    "this_dir = osp.join(data_dir, dataset_name)\n",
    "df = pd.read_csv(osp.join(this_dir, f'bikes.csv'), sep=',')\n",
    "df.describe(include='all')\n",
    "print('Location of nulls')\n",
    "print(df.isna().sum())\n",
    "df_nonulls = df.dropna()\n",
    "print(f'Shape of full dataset: {df.shape}')\n",
    "print(f'Shape of cleaned dataset: {df_nonulls.shape}')\n",
    "df.to_csv(osp.join(this_dir, f'{dataset_name}_clean.csv'), index=False)\n",
    "df_nonulls.convert_dtypes().to_csv(osp.join(this_dir, f'{dataset_name}_nonulls.csv'), index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of nulls\n",
      "id             0\n",
      "bike_name      0\n",
      "city_posted    0\n",
      "km_driven      0\n",
      "color          0\n",
      "fuel_type      0\n",
      "price          0\n",
      "model_year     0\n",
      "owner_type     0\n",
      "dtype: int64\n",
      "Shape of full dataset: (4786, 9)\n",
      "Shape of cleaned dataset: (4786, 9)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'bikes-dekho'\n",
    "this_dir = osp.join(data_dir, dataset_name)\n",
    "df = pd.read_csv(osp.join(this_dir, f'bikes-dekho.csv'), sep=',')\n",
    "df.describe(include='all')\n",
    "print('Location of nulls')\n",
    "print(df.isna().sum())\n",
    "df_nonulls = df.dropna()\n",
    "print(f'Shape of full dataset: {df.shape}')\n",
    "print(f'Shape of cleaned dataset: {df_nonulls.shape}')\n",
    "df.to_csv(osp.join(this_dir, f'{dataset_name}_clean.csv'), index=False)\n",
    "df_nonulls.convert_dtypes().to_csv(osp.join(this_dir, f'{dataset_name}_nonulls.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of nulls\n",
      "id             0\n",
      "bike_name      0\n",
      "city_posted    0\n",
      "km_driven      0\n",
      "color          2\n",
      "fuel_type      0\n",
      "price          0\n",
      "model_year     0\n",
      "owner_type     0\n",
      "dtype: int64\n",
      "Shape of full dataset: (9003, 9)\n",
      "Shape of cleaned dataset: (9001, 9)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'bikes-wale'\n",
    "this_dir = osp.join(data_dir, dataset_name)\n",
    "df = pd.read_csv(osp.join(this_dir, f'bikes-wale.csv'), sep=',')\n",
    "df.describe(include='all')\n",
    "print('Location of nulls')\n",
    "print(df.isna().sum())\n",
    "df_nonulls = df.dropna()\n",
    "print(f'Shape of full dataset: {df.shape}')\n",
    "print(f'Shape of cleaned dataset: {df_nonulls.shape}')\n",
    "df.to_csv(osp.join(this_dir, f'{dataset_name}_clean.csv'), index=False)\n",
    "df_nonulls.convert_dtypes().to_csv(osp.join(this_dir, f'{dataset_name}_nonulls.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of nulls\n",
      "beer_name              0\n",
      "brew_factory_name      2\n",
      "style                  2\n",
      "abv                  898\n",
      "dtype: int64\n",
      "Shape of full dataset: (7345, 4)\n",
      "Shape of cleaned dataset: (6443, 4)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'beer'\n",
    "this_dir = osp.join(data_dir, dataset_name)\n",
    "df = pd.read_csv(osp.join(this_dir, f'beer.csv'), sep=',')\n",
    "df.describe(include='all')\n",
    "print('Location of nulls')\n",
    "print(df.isna().sum())\n",
    "df_nonulls = df.dropna()\n",
    "print(f'Shape of full dataset: {df.shape}')\n",
    "print(f'Shape of cleaned dataset: {df_nonulls.shape}')\n",
    "df.to_csv(osp.join(this_dir, f'{dataset_name}_clean.csv'), index=False)\n",
    "df_nonulls.convert_dtypes().to_csv(osp.join(this_dir, f'{dataset_name}_nonulls.csv'), index=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-2c0b046e",
   "language": "python",
   "display_name": "PyCharm (GRIMP)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}